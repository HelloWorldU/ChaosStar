{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7061216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from app.agent import ChaosStar\n",
    "\n",
    "agent = await ChaosStar.create(llm_name=\"anthropic\", name=\"ChaosStar\", next_step_prompt=\"test first\", max_steps=2)\n",
    "result = await agent.run(\"Hello, Claude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858a130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from app.agent import StreamChaosStar\n",
    "\n",
    "agent = await StreamChaosStar.create(llm_name=\"anthropic\", name=\"ChaosStarStream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071d355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import sys\n",
    "import asyncio\n",
    "\n",
    "if sys.platform.startswith(\"win\"):\n",
    "    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())\n",
    "sys.path.append(\"..\")\n",
    "from app.agent import StreamChaosStar\n",
    "\n",
    "agent = None\n",
    "prompt = \"\"\"\n",
    "我正在为一家初创公司制定2025年的市场进入策略。公司开发了一款基于AI的个人健康监测设备，类似智能手表但专注医疗级数据采集。我需要你：\n",
    "\n",
    "分析当前可穿戴医疗设备市场的竞争格局和趋势\n",
    "识别目标市场和用户画像\n",
    "评估进入壁垒和监管要求\n",
    "制定差异化定位策略\n",
    "估算初期市场投入预算\n",
    "\n",
    "请用结构化思考方式分析，包括数据支撑、风险评估和具体行动建议。\n",
    "\"\"\"\n",
    "\n",
    "async def main():\n",
    "    global agent\n",
    "    agent = await StreamChaosStar.create(llm_name=\"anthropic\", name=\"ChaosStarStream\")\n",
    "    async for res in agent.run(prompt, stream=True):\n",
    "        print(res)\n",
    "    await agent.cleanup()\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2057d625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from app.llm import LLM\n",
    "\n",
    "claude = LLM.for_config(\"anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7cfff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing connection to https://www.google.com with proxy http://127.0.0.1:7897\n",
      "✅ Success!\n",
      "Status Code: 200\n",
      "Response Time: 1.21s\n",
      "Content Length: 167497 characters\n",
      "Title: <title>Google</title>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def test_google_with_proxy():\n",
    "    \"\"\"Test accessing Google with proxy\"\"\"\n",
    "    \n",
    "    proxy = \"http://127.0.0.1:7897\" # Change to your own proxy if needed\n",
    "    proxies = {\n",
    "        'http': proxy,\n",
    "        'https': proxy\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    \n",
    "    url = \"https://www.google.com\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Testing connection to {url} with proxy {proxy}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = requests.get(\n",
    "            url, \n",
    "            headers=headers, \n",
    "            proxies=proxies, \n",
    "            timeout=10\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"✅ Success!\")\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        print(f\"Response Time: {end_time - start_time:.2f}s\")\n",
    "        print(f\"Content Length: {len(response.text)} characters\")\n",
    "        print(f\"Title: {response.text[response.text.find('<title>'):response.text.find('</title>') + 8] if '<title>' in response.text else 'No title found'}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed: {e}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_google_with_proxy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5388747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from app.llm import LLM\n",
    "\n",
    "claude = LLM.for_config(\"anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2d0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude.thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fc029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_py_lines(root):\n",
    "    total_lines = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.py'):\n",
    "                file_path = os.path.join(dirpath, filename)\n",
    "                try:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        lines = f.readlines()\n",
    "                        line_count = len([line for line in lines if line.strip()])\n",
    "                        print(f\"{file_path}: {line_count} lines\")\n",
    "                        total_lines += line_count\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not read {file_path}: {e}\")\n",
    "    print(f\"Total lines: {total_lines}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    root_dir = r'C:\\Users\\Administrator\\Desktop\\LLM\\ChaosStar'\n",
    "    count_py_lines(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0721f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp.types import ClientRequest, CallToolRequest\n",
    "\n",
    "params = {'name': 'broswer_use', 'action': 'web_search', 'url': None, 'index': None, 'text': None, 'scroll_amount': None, 'tab_id': None, 'query': 'Elon Musk interesting events 2025', 'goal': None, 'keys': None, 'seconds': None}\n",
    "method=\"tools/call\"\n",
    "request = ClientRequest(CallToolRequest(method=method, params=params))\n",
    "dump = request.model_dump(by_alias=True, mode=\"json\", exclude_none=True)\n",
    "print(dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f063554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import tomllib\n",
    "import httpx\n",
    "from anthropic import AsyncAnthropic\n",
    "from app.config import PROJECT_ROOT\n",
    "\n",
    "file_path = PROJECT_ROOT /\"config\" / \"config.example.test.toml\"\n",
    "with file_path.open(\"rb\") as f:\n",
    "    llm_config = tomllib.load(f)\n",
    "api_key = llm_config.get(\"llm\", None).get(\"anthropic\", {}).get(\"api_key\", None)\n",
    "local_proxy = llm_config.get(\"llm\", None).get(\"anthropic\", {}).get(\"proxy\", None)\n",
    "proxy_client = httpx.AsyncClient(\n",
    "    proxy=httpx.Proxy(url=local_proxy),\n",
    "    timeout=30,\n",
    ")\n",
    "\n",
    "client = AsyncAnthropic(\n",
    "    api_key=api_key,  # This is the default and can be omitted\n",
    "    base_url=\"https://api.anthropic.com\",\n",
    "    http_client=proxy_client\n",
    ")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    message = await client.messages.create(\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello, Claude\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"claude-3-5-haiku-20241022\",\n",
    "    )\n",
    "    print(message.content)\n",
    "\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
